#!/usr/bin/env python3
"""
å‘é‡åŒ–æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬ä¸“é—¨å±•ç¤ºæ–‡æœ¬å‘é‡åŒ–åŠŸèƒ½ï¼š
1. æ–‡æœ¬å‘é‡åŒ–è¿‡ç¨‹
2. å‘é‡æ•°æ®åˆ†æ
3. å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
4. å‘é‡å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
"""

import asyncio
import sys
import math
from pathlib import Path
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from haiku.rag.embeddings import get_embedder
from haiku.rag.config import Config


def print_header(title: str, char: str = "=", width: int = 80):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{char * width}")
    print(f"{title:^{width}}")
    print(f"{char * width}")


def print_section(title: str, char: str = "-", width: int = 60):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{char * width}")
    print(f" {title}")
    print(f"{char * width}")


def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
    if len(vec1) != len(vec2):
        raise ValueError("å‘é‡ç»´åº¦ä¸åŒ¹é…")
    
    dot_product = sum(a * b for a, b in zip(vec1, vec2))
    magnitude1 = math.sqrt(sum(a * a for a in vec1))
    magnitude2 = math.sqrt(sum(a * a for a in vec2))
    
    if magnitude1 == 0 or magnitude2 == 0:
        return 0.0
    
    return dot_product / (magnitude1 * magnitude2)


def analyze_vector(vector: List[float], name: str = "å‘é‡") -> Dict[str, Any]:
    """åˆ†æå‘é‡çš„ç»Ÿè®¡ç‰¹æ€§"""
    if not vector:
        return {}
    
    return {
        "name": name,
        "dimension": len(vector),
        "min_value": min(vector),
        "max_value": max(vector),
        "mean": sum(vector) / len(vector),
        "magnitude": math.sqrt(sum(x * x for x in vector)),
        "non_zero_count": sum(1 for x in vector if abs(x) > 1e-10),
        "sparsity": 1 - (sum(1 for x in vector if abs(x) > 1e-10) / len(vector))
    }


async def demo_embeddings():
    """æ¼”ç¤ºå‘é‡åŒ–åŠŸèƒ½"""
    
    print_header("æ–‡æœ¬å‘é‡åŒ–æ¼”ç¤º")
    
    # æ£€æŸ¥åµŒå…¥é…ç½®
    print_section("1. åµŒå…¥æ¨¡å‹é…ç½®")
    print(f"æä¾›å•†: {Config.EMBEDDINGS_PROVIDER}")
    print(f"æ¨¡å‹: {Config.EMBEDDINGS_MODEL}")
    print(f"å‘é‡ç»´åº¦: {Config.EMBEDDINGS_VECTOR_DIM}")
    
    try:
        embedder = get_embedder()
        print(f"âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®æˆ–å®‰è£…ç›¸åº”çš„ä¾èµ–åŒ…")
        return
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "è³ä¹‹å‘³æ§è‚¡æœ‰é™å…¬å¸å°‡èˆ‰è¡Œè‚¡æ±é€±å¹´å¤§æœƒ",
        "The company will hold an annual general meeting",
        "å…¬å¸è²¡å‹™è¡¨ç¾è‰¯å¥½ï¼Œç‡Ÿæ”¶å¢é•·é¡¯è‘—",
        "Financial performance is strong with significant revenue growth",
        "è‘£äº‹æœƒå»ºè­°æ´¾ç™¼è‚¡æ¯æ¯è‚¡0.05æ¸¯å…ƒ",
        "The board recommends a dividend of HK$0.05 per share"
    ]
    
    print_section("2. æ–‡æœ¬å‘é‡åŒ–éç¨‹")
    
    embeddings = []
    for i, text in enumerate(test_texts):
        print(f"\nğŸ“ æ–‡æœ¬ {i+1}: {text}")
        
        try:
            embedding = await embedder.embed(text)
            embeddings.append(embedding)
            
            # åˆ†æå‘é‡
            stats = analyze_vector(embedding, f"æ–‡æœ¬{i+1}")
            print(f"   âœ… å‘é‡åŒ–æˆåŠŸ")
            print(f"   ğŸ“Š ç¶­åº¦: {stats['dimension']}")
            print(f"   ğŸ“Š ç¯„åœ: [{stats['min_value']:.6f}, {stats['max_value']:.6f}]")
            print(f"   ğŸ“Š å‡å€¼: {stats['mean']:.6f}")
            print(f"   ğŸ“Š æ¨¡é•·: {stats['magnitude']:.6f}")
            print(f"   ğŸ“Š ç¨€ç–åº¦: {stats['sparsity']:.2%}")
            
            # æ˜¾ç¤ºå‘é‡çš„å‰10ä¸ªå’Œå10ä¸ªç»´åº¦
            print(f"   ğŸ”¢ å‰10ç¶­: {embedding[:10]}")
            if len(embedding) > 10:
                print(f"   ğŸ”¢ å¾Œ10ç¶­: {embedding[-10:]}")
                
        except Exception as e:
            print(f"   âŒ å‘é‡åŒ–å¤±è´¥: {e}")
            embeddings.append(None)
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    print_section("3. å‘é‡ç›¸ä¼¼åº¦åˆ†æ")
    
    valid_embeddings = [(i, emb) for i, emb in enumerate(embeddings) if emb is not None]
    
    if len(valid_embeddings) >= 2:
        print("ğŸ“Š ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ:")
        print("   ", end="")
        for i, _ in valid_embeddings:
            print(f"æ–‡æœ¬{i+1:2d}", end="  ")
        print()
        
        for i, (idx1, emb1) in enumerate(valid_embeddings):
            print(f"æ–‡æœ¬{idx1+1:2d}", end=" ")
            for j, (idx2, emb2) in enumerate(valid_embeddings):
                if i == j:
                    similarity = 1.0
                else:
                    similarity = cosine_similarity(emb1, emb2)
                print(f"{similarity:6.3f}", end="  ")
            print()
        
        # æ‰¾å‡ºæœ€ç›¸ä¼¼å’Œæœ€ä¸ç›¸ä¼¼çš„æ–‡æœ¬å¯¹
        max_similarity = -1
        min_similarity = 2
        max_pair = None
        min_pair = None
        
        for i, (idx1, emb1) in enumerate(valid_embeddings):
            for j, (idx2, emb2) in enumerate(valid_embeddings):
                if i < j:  # é¿å…é‡å¤è®¡ç®—
                    similarity = cosine_similarity(emb1, emb2)
                    if similarity > max_similarity:
                        max_similarity = similarity
                        max_pair = (idx1, idx2)
                    if similarity < min_similarity:
                        min_similarity = similarity
                        min_pair = (idx1, idx2)
        
        if max_pair:
            print(f"\nğŸ”¥ æœ€ç›¸ä¼¼çš„æ–‡æœ¬å°:")
            print(f"   æ–‡æœ¬{max_pair[0]+1}: {test_texts[max_pair[0]]}")
            print(f"   æ–‡æœ¬{max_pair[1]+1}: {test_texts[max_pair[1]]}")
            print(f"   ç›¸ä¼¼åº¦: {max_similarity:.4f}")
        
        if min_pair:
            print(f"\nâ„ï¸  æœ€ä¸ç›¸ä¼¼çš„æ–‡æœ¬å°:")
            print(f"   æ–‡æœ¬{min_pair[0]+1}: {test_texts[min_pair[0]]}")
            print(f"   æ–‡æœ¬{min_pair[1]+1}: {test_texts[min_pair[1]]}")
            print(f"   ç›¸ä¼¼åº¦: {min_similarity:.4f}")
    
    # å‘é‡åˆ†å¸ƒåˆ†æ
    print_section("4. å‘é‡åˆ†å¸ƒåˆ†æ")
    
    if valid_embeddings:
        all_values = []
        for _, emb in valid_embeddings:
            all_values.extend(emb)
        
        print(f"ğŸ“Š æ‰€æœ‰å‘é‡å€¼çµ±è¨ˆ:")
        print(f"   ç¸½æ•¸æ“šé»: {len(all_values)}")
        print(f"   æœ€å°å€¼: {min(all_values):.6f}")
        print(f"   æœ€å¤§å€¼: {max(all_values):.6f}")
        print(f"   å‡å€¼: {sum(all_values)/len(all_values):.6f}")
        
        # è®¡ç®—åˆ†å¸ƒ
        positive_count = sum(1 for x in all_values if x > 0)
        negative_count = sum(1 for x in all_values if x < 0)
        zero_count = len(all_values) - positive_count - negative_count
        
        print(f"   æ­£å€¼æ¯”ä¾‹: {positive_count/len(all_values):.2%}")
        print(f"   è² å€¼æ¯”ä¾‹: {negative_count/len(all_values):.2%}")
        print(f"   é›¶å€¼æ¯”ä¾‹: {zero_count/len(all_values):.2%}")
        
        # ç®€å•çš„åˆ†å¸ƒç›´æ–¹å›¾
        print(f"\nğŸ“ˆ å€¼åˆ†å¸ƒç›´æ–¹å›¾ (10å€‹å€é–“):")
        min_val, max_val = min(all_values), max(all_values)
        bin_width = (max_val - min_val) / 10
        bins = [0] * 10
        
        for val in all_values:
            bin_idx = min(int((val - min_val) / bin_width), 9)
            bins[bin_idx] += 1
        
        max_count = max(bins)
        for i, count in enumerate(bins):
            bin_start = min_val + i * bin_width
            bin_end = min_val + (i + 1) * bin_width
            bar_length = int(count / max_count * 40) if max_count > 0 else 0
            bar = "â–ˆ" * bar_length
            print(f"   [{bin_start:7.3f}, {bin_end:7.3f}): {bar} ({count})")
    
    print_section("5. å‘é‡åŒ–è³ªé‡è©•ä¼°")
    
    if len(valid_embeddings) >= 2:
        # è¯„ä¼°å‘é‡çš„åŒºåˆ†åº¦
        similarities = []
        for i, (idx1, emb1) in enumerate(valid_embeddings):
            for j, (idx2, emb2) in enumerate(valid_embeddings):
                if i < j:
                    similarities.append(cosine_similarity(emb1, emb2))
        
        avg_similarity = sum(similarities) / len(similarities)
        similarity_variance = sum((s - avg_similarity) ** 2 for s in similarities) / len(similarities)
        
        print(f"ğŸ“Š å‘é‡å€åˆ†åº¦åˆ†æ:")
        print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.4f}")
        print(f"   ç›¸ä¼¼åº¦æ–¹å·®: {similarity_variance:.6f}")
        print(f"   ç›¸ä¼¼åº¦æ¨™æº–å·®: {math.sqrt(similarity_variance):.4f}")
        
        # è¯„ä¼°æ ‡å‡†
        if avg_similarity < 0.3:
            print("   âœ… å‘é‡å€åˆ†åº¦è‰¯å¥½ (å¹³å‡ç›¸ä¼¼åº¦ < 0.3)")
        elif avg_similarity < 0.7:
            print("   âš ï¸  å‘é‡å€åˆ†åº¦ä¸­ç­‰ (0.3 â‰¤ å¹³å‡ç›¸ä¼¼åº¦ < 0.7)")
        else:
            print("   âŒ å‘é‡å€åˆ†åº¦è¼ƒå·® (å¹³å‡ç›¸ä¼¼åº¦ â‰¥ 0.7)")
        
        if math.sqrt(similarity_variance) > 0.1:
            print("   âœ… å‘é‡å·®ç•°æ€§è‰¯å¥½ (æ¨™æº–å·® > 0.1)")
        else:
            print("   âš ï¸  å‘é‡å·®ç•°æ€§è¼ƒå° (æ¨™æº–å·® â‰¤ 0.1)")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ–‡æœ¬å‘é‡åŒ–æ¼”ç¤º")
    
    try:
        await demo_embeddings()
        
        print_header("æ¼”ç¤ºå®Œæˆ", char="*")
        print("ğŸ’¡ æç¤ºï¼šä¸åŒçš„åµŒå…¥æ¨¡å‹æœƒç”¢ç”Ÿä¸åŒçš„å‘é‡è¡¨ç¤º")
        print("ğŸ’¡ å»ºè­°ï¼šé¸æ“‡é©åˆæ‚¨èªè¨€å’Œé ˜åŸŸçš„åµŒå…¥æ¨¡å‹ä»¥ç²å¾—æœ€ä½³æ•ˆæœ")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºéç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
